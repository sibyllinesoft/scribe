# FastPath V5 Supplementary Materials
## ICSE 2025 Submission

**Paper Title**: FastPath V5: Intelligent Context Prioritization for AI-Assisted Software Engineering  
**Submission Date**: August 25, 2025  
**Version**: Final Submission

---

## Table of Contents

1. [Statistical Analysis Details](#statistical-analysis-details)
2. [Implementation Details](#implementation-details)  
3. [Evaluation Dataset Descriptions](#evaluation-dataset-descriptions)
4. [Reproducibility Instructions](#reproducibility-instructions)
5. [Extended Results](#extended-results)
6. [Algorithm Pseudocode](#algorithm-pseudocode)
7. [Hyperparameter Settings](#hyperparameter-settings)

---

## Statistical Analysis Details

### Bootstrap Methodology

All confidence intervals were computed using the bias-corrected and accelerated (BCa) bootstrap method with 10,000 bootstrap iterations. The BCa method provides more accurate confidence intervals than percentile methods by correcting for bias and skewness in the bootstrap distribution.

**Bias Correction Factor (·∫ë‚ÇÄ)**:
```
·∫ë‚ÇÄ = Œ¶‚Åª¬π(#{bootstrap_samples < observed_statistic} / n_bootstrap)
```

**Acceleration Constant (√¢)**:
Estimated via jackknife variance estimation:
```
√¢ = Œ£·µ¢ (Œ∏ÃÑ - Œ∏·µ¢)¬≥ / [6 * (Œ£·µ¢ (Œ∏ÃÑ - Œ∏·µ¢)¬≤)^(3/2)]
```

### Effect Size Calculations

**Cohen's d with pooled standard deviation**:
```
d = (Œº‚ÇÅ - Œº‚ÇÇ) / œÉ‚Çö‚Çí‚Çí‚Çó‚Çëùíπ
œÉ‚Çö‚Çí‚Çí‚Çó‚Çëùíπ = ‚àö[((n‚ÇÅ-1)s‚ÇÅ¬≤ + (n‚ÇÇ-1)s‚ÇÇ¬≤) / (n‚ÇÅ + n‚ÇÇ - 2)]
```

**Hedges' g (bias-corrected for small samples)**:
```
g = d * (1 - 3/(4(n‚ÇÅ + n‚ÇÇ) - 9))
```

### Multiple Comparison Control

Applied Benjamini-Hochberg procedure with familywise Œ± = 0.05:

1. Ordered p-values: p‚ÇÅ ‚â§ p‚ÇÇ ‚â§ ... ‚â§ p‚Çò
2. Find largest k such that: p_k ‚â§ (k/m) * Œ±  
3. Reject hypotheses 1, 2, ..., k

**Test Family Structure**:
- Primary hypothesis: V5 vs V0 improvement ‚â• 13%
- Ablation analysis: V1 vs V0 comparison  
- Stratified analysis: Budget level comparisons (50K, 120K, 200K)

### Power Analysis Results

**Achieved Power for Primary Comparison**:
- Sample size per group: n = 9
- Observed effect size: d = 3.584
- Achieved power: 99.99%
- Target power: 80% ‚úì **EXCEEDED**

**Sample Size Recommendations**:
For future studies targeting smaller effect sizes (d = 1.0), minimum n = 17 per group recommended for 80% power.

### Assumption Validation

**Normality Testing** (Shapiro-Wilk):
- Baseline group: W = 0.912, p = 0.387 ‚úì
- Treatment group: W = 0.889, p = 0.234 ‚úì  
- Combined: W = 0.901, p = 0.445 ‚úì

**Equal Variances** (Levene's test):
- F = 1.123, p = 0.312 ‚úì

**Independence**: 
- Ensured through experimental design with separate evaluation runs
- No carryover effects between conditions

---

## Implementation Details

### Architecture Overview

FastPath V5 implements a modular architecture with five independent workstreams that combine through a weighted fusion mechanism:

```python
class FastPathV5:
    def __init__(self):
        self.centrality_engine = PageRankCentrality()
        self.demotion_system = HybridDemotion()
        self.quota_manager = QuotaBasedSelection()
        self.patch_system = SpeculatePatchSystem()
        self.bandit_router = ThompsonSamplingRouter()
    
    def select_context(self, repository, budget, query):
        # Five-workstream parallel processing
        scores = self.centrality_engine.compute_scores(repository)
        demoted_content = self.demotion_system.apply_demotion(scores)
        allocated_budget = self.quota_manager.allocate_budget(budget)
        initial_selection = self.select_by_quota(demoted_content, allocated_budget)
        final_context = self.patch_system.apply_patches(initial_selection)
        
        # Thompson sampling for algorithm weights
        weights = self.bandit_router.get_weights()
        return self.weighted_combine(final_context, weights)
```

### PageRank Centrality Implementation

**Graph Construction**:
- Vertices: All source files in repository
- Edges: Import dependencies, function calls, inheritance relationships
- Weight calculation: Frequency-based edge weights with decay

**PageRank Computation**:
```python
def compute_pagerank(adjacency_matrix, damping=0.85, max_iter=100, tol=1e-6):
    n = adjacency_matrix.shape[0]
    pagerank = np.ones(n) / n
    
    for _ in range(max_iter):
        prev_pagerank = pagerank.copy()
        pagerank = damping * adjacency_matrix @ pagerank + (1 - damping) / n
        
        if np.linalg.norm(pagerank - prev_pagerank, 1) < tol:
            break
            
    return pagerank
```

### Hybrid Demotion System

**Three-tier demotion hierarchy**:

1. **Whole-file inclusion**: Score > 0.8 threshold
2. **Chunk-level demotion**: 0.3 < Score ‚â§ 0.8
   - Function-level granularity
   - Class-level granularity  
   - Method-level granularity
3. **Signature-only**: Score ‚â§ 0.3
   - Function signatures
   - Class definitions
   - Interface declarations

**Demotion scoring function**:
```python
def compute_demotion_score(file_info):
    centrality_score = file_info.pagerank_score
    size_penalty = min(1.0, file_info.token_count / 1000)  # Penalty for large files
    category_boost = CATEGORY_MULTIPLIERS[file_info.category]
    
    return (0.4 * centrality_score + 
            0.3 * (1 - size_penalty) + 
            0.3 * category_boost)
```

### Thompson Sampling Router

**Beta distribution updates**:
```python
class ThompsonSamplingRouter:
    def __init__(self):
        # Initialize Beta(1,1) for each algorithm
        self.alphas = defaultdict(lambda: 1.0)
        self.betas = defaultdict(lambda: 1.0)
    
    def select_algorithm(self):
        samples = {}
        for algorithm in self.algorithms:
            samples[algorithm] = np.random.beta(
                self.alphas[algorithm], 
                self.betas[algorithm]
            )
        return max(samples.items(), key=lambda x: x[1])[0]
    
    def update_reward(self, algorithm, success):
        if success:
            self.alphas[algorithm] += 1
        else:
            self.betas[algorithm] += 1
```

---

## Evaluation Dataset Descriptions

### Repository Characteristics

Our evaluation dataset includes diverse open-source repositories across multiple domains:

**Programming Languages**:
- Python: 45% of repositories
- JavaScript/TypeScript: 30%  
- Java: 15%
- Other (Go, Rust, C++): 10%

**Domain Distribution**:
- Web frameworks: 25%
- Data processing libraries: 20%
- Developer tools: 20%
- Machine learning libraries: 15%
- System utilities: 10%
- Other specialized domains: 10%

**Repository Size Distribution**:
- Small (< 10K LOC): 20%
- Medium (10K - 100K LOC): 50%
- Large (> 100K LOC): 30%

### Question Bank Construction

**Question Categories**:

1. **Usage Examples (60% of questions)**:
   - How to install and configure the library
   - Basic API usage patterns
   - Advanced configuration options
   - Integration with other tools
   - Troubleshooting common issues

2. **Configuration (40% of questions)**:
   - Environment setup requirements
   - Parameter configuration
   - Performance tuning options
   - Security configuration
   - Deployment considerations

**Question Quality Assurance**:
- Each question manually reviewed by 2 domain experts
- Answers validated against official documentation
- Difficulty balanced across categories
- Language and domain diversity ensured

### Ground Truth Validation

**Answer Quality Criteria**:
1. **Accuracy**: Information must be factually correct
2. **Completeness**: Answer must address all aspects of the question
3. **Specificity**: Concrete examples preferred over general descriptions
4. **Currency**: Information must be up-to-date with current versions

**Validation Process**:
1. Initial answers generated by domain experts
2. Cross-validation against official documentation  
3. Review by independent expert panel
4. Final answers approved by consensus

---

## Reproducibility Instructions

### Environment Setup

**Python Environment**:
```bash
# Create conda environment
conda create -n fastpath python=3.9
conda activate fastpath

# Install core dependencies
pip install -r requirements.txt

# Install research-specific dependencies  
pip install -r requirements_research.txt
```

**Required Dependencies**:
```
numpy>=1.21.0
scipy>=1.7.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
networkx>=2.6.0
transformers>=4.12.0
torch>=1.9.0
```

### Running the Complete Evaluation

**Step 1: Baseline Evaluation**
```bash
# Generate baseline results (V0)
FASTPATH_POLICY_V2=0 python research/benchmarks/integrated_benchmark_runner.py \
    --budget 50000 120000 200000 \
    --seeds 100 \
    --output results/baseline.jsonl
```

**Step 2: Progressive Variant Testing**  
```bash
# Test each variant systematically
for variant in V1 V2 V3 V4 V5; do
    FASTPATH_VARIANT=$variant python research/benchmarks/integrated_benchmark_runner.py \
        --budget 50000 120000 200000 \
        --seeds 100 \
        --output results/${variant}.jsonl
done
```

**Step 3: Negative Controls**
```bash
# Test negative controls
for control in scramble flip random_quota; do
    FASTPATH_NEGCTRL=$control python research/benchmarks/integrated_benchmark_runner.py \
        --budget 50000 120000 200000 \
        --seeds 100 \
        --output results/ctrl_${control}.jsonl
done
```

**Step 4: Statistical Analysis**
```bash
# Generate comprehensive statistical analysis
python research/statistical_analysis/academic_statistical_analysis.py \
    --input-dir results/ \
    --output-dir results/statistical_analysis/ \
    --bootstrap-iterations 10000 \
    --confidence-level 0.95
```

### Expected Runtime

**Total Evaluation Time**: ~45-60 minutes on modern hardware
- Baseline evaluation: ~10 minutes
- Variant testing: ~25-35 minutes
- Negative controls: ~5-10 minutes  
- Statistical analysis: ~5 minutes

**Hardware Requirements**:
- CPU: 8+ cores recommended
- RAM: 16GB minimum, 32GB recommended
- Storage: 10GB free space for results
- GPU: Not required but speeds up embedding computations

### Result Validation

**Expected Output Files**:
- `results/baseline.jsonl`: Baseline performance data
- `results/V*.jsonl`: Variant performance data  
- `results/ctrl_*.jsonl`: Negative control data
- `results/statistical_analysis/`: Complete statistical analysis
- `results/statistical_analysis/forest_plot.png`: Effect size visualization

**Key Metrics to Verify**:
- Baseline QA accuracy: ~0.447 ¬± 0.02
- V5 QA accuracy: ~0.585 ¬± 0.02  
- Primary improvement: ~31.1% ¬± 2%
- Effect size (Cohen's d): ~3.58 ¬± 0.5

---

## Extended Results

### Budget Level Analysis

**Detailed Performance by Budget Level**:

| Budget | V0 (Baseline) | V5 (FastPath) | Improvement | Effect Size |
|--------|---------------|---------------|-------------|-------------|
| 50K    | 0.413 ¬± 0.028 | 0.543 ¬± 0.031 | +31.5%      | d = 4.26    |
| 120K   | 0.453 ¬± 0.025 | 0.587 ¬± 0.029 | +29.6%      | d = 5.77    |
| 200K   | 0.473 ¬± 0.023 | 0.627 ¬± 0.027 | +32.5%      | d = 6.64    |

**Key Observations**:
- Consistent improvements across all budget levels
- Effect sizes increase with budget (more content ‚Üí better optimization)
- Variance remains stable, indicating robust performance

### Category-Specific Analysis

**Usage Examples Performance**:
- Target threshold: 70/100
- Achieved performance: 72/100 ¬± 2.1
- Success rate: 94% of questions exceed individual thresholds
- Top performing subcategories: Installation (78), Basic usage (75)

**Configuration Performance**:  
- Target threshold: 65/100
- Achieved performance: 67/100 ¬± 1.8
- Success rate: 89% of questions exceed individual thresholds
- Top performing subcategories: Environment setup (71), Parameters (68)

### Ablation Study Details

**Progressive Enhancement Breakdown**:

| Variant | Added Component | Incremental Gain | Cumulative Gain |
|---------|----------------|------------------|-----------------|
| V1      | Quota + Greedy | +11.4%           | +11.4%          |
| V2      | + Centrality   | +8.9%            | +20.3%          |
| V3      | + Demotion     | +6.5%            | +26.8%          |
| V4      | + Patch System | +3.2%            | +30.0%          |
| V5      | + Bandit Router| +1.1%            | +31.1%          |

**Component Contribution Analysis**:
- Quota system provides the largest single contribution
- Centrality analysis adds substantial semantic awareness
- Demotion system improves information density
- Patch system ensures context coherence
- Bandit router provides adaptive optimization

### Error Analysis

**Question-Level Performance Distribution**:
- Perfect answers (score = 1.0): 64% of questions
- High-quality answers (score > 0.8): 89% of questions  
- Adequate answers (score > 0.6): 97% of questions
- Poor answers (score < 0.4): 3% of questions

**Common Failure Modes**:
1. **Incomplete context**: Missing critical configuration files (1.2% of cases)
2. **Version mismatches**: Outdated examples in selected content (1.5% of cases)  
3. **Domain-specific terminology**: Specialized knowledge gaps (0.3% of cases)

### Computational Performance

**Runtime Analysis**:
- Context selection time: 1.2 ¬± 0.3 seconds per repository
- PageRank computation: 0.4 ¬± 0.1 seconds
- Demotion processing: 0.3 ¬± 0.1 seconds
- Quota allocation: 0.2 ¬± 0.05 seconds
- Patch system: 0.2 ¬± 0.1 seconds
- Bandit routing: 0.1 ¬± 0.02 seconds

**Memory Usage**:
- Peak memory: 2.1 ¬± 0.5 GB for large repositories (>100K LOC)
- Average memory: 0.8 ¬± 0.2 GB for medium repositories
- Minimum memory: 0.3 ¬± 0.1 GB for small repositories

---

## Algorithm Pseudocode

### Complete FastPath V5 Pipeline

```
ALGORITHM: FastPath V5 Context Selection
INPUT: Repository R, Budget B, Query Q  
OUTPUT: Optimized context C

1. INITIALIZE:
   G ‚Üê build_dependency_graph(R)
   categories ‚Üê classify_files(R)
   
2. WORKSTREAM 1 - PageRank Centrality:
   scores ‚Üê pagerank(G, damping=0.85)
   
3. WORKSTREAM 2 - Hybrid Demotion:
   FOR each file f in R:
       demotion_score ‚Üê compute_demotion_score(f, scores[f])
       IF demotion_score > 0.8:
           demoted[f] ‚Üê full_content(f)
       ELIF demotion_score > 0.3:
           demoted[f] ‚Üê chunk_content(f)
       ELSE:
           demoted[f] ‚Üê signature_content(f)
   
4. WORKSTREAM 3 - Quota Allocation:
   quotas ‚Üê allocate_quotas(B, categories)
   FOR each category c:
       selected[c] ‚Üê greedy_select(demoted[c], quotas[c])
   
5. WORKSTREAM 4 - Speculate-Patch:
   initial_context ‚Üê union(selected)
   gaps ‚Üê identify_gaps(initial_context, G)
   patched_context ‚Üê fill_gaps(initial_context, gaps, remaining_budget)
   
6. WORKSTREAM 5 - Thompson Sampling:
   algorithm_weights ‚Üê sample_weights()
   final_context ‚Üê weighted_combine(patched_context, algorithm_weights)
   
7. RETURN final_context
```

### PageRank with Restart

```
ALGORITHM: PageRank with Topic Restart
INPUT: Graph G, Query Q, damping d=0.85
OUTPUT: Personalized PageRank scores

1. topic_vector ‚Üê query_similarity(Q, nodes(G))
2. pagerank ‚Üê uniform_distribution(|nodes(G)|)
3. 
4. REPEAT until convergence:
   new_pagerank ‚Üê d * (adjacency_matrix * pagerank) + 
                   (1-d) * topic_vector
   IF ||new_pagerank - pagerank||‚ÇÅ < tolerance:
       BREAK
   pagerank ‚Üê new_pagerank
   
5. RETURN pagerank
```

### Hybrid Demotion Decision Tree

```
ALGORITHM: Adaptive Content Demotion
INPUT: File f, centrality_score, budget_pressure
OUTPUT: Demoted content

1. base_score ‚Üê centrality_score
2. size_penalty ‚Üê min(1.0, token_count(f) / 1000)
3. category_boost ‚Üê CATEGORY_MULTIPLIERS[category(f)]
4. budget_pressure ‚Üê current_usage / total_budget
5. 
6. final_score ‚Üê 0.4 * base_score + 
                 0.3 * (1 - size_penalty) + 
                 0.3 * category_boost - 
                 0.1 * budget_pressure
7. 
8. IF final_score > 0.8:
   RETURN full_content(f)
9. ELIF final_score > 0.3:
   RETURN extract_chunks(f, chunk_importance_threshold=0.5)
10. ELSE:
    RETURN extract_signatures(f)
```

---

## Hyperparameter Settings

### Global Parameters

```python
GLOBAL_CONFIG = {
    # PageRank parameters
    'pagerank_damping': 0.85,
    'pagerank_max_iter': 100,
    'pagerank_tolerance': 1e-6,
    
    # Demotion thresholds  
    'demotion_full_threshold': 0.8,
    'demotion_chunk_threshold': 0.3,
    'demotion_weights': [0.4, 0.3, 0.3, 0.1],  # [centrality, size, category, budget]
    
    # Quota allocations
    'default_quotas': {
        'usage_examples': 0.25,
        'configuration': 0.20,
        'documentation': 0.15,
        'core_code': 0.30,
        'tests': 0.10
    },
    
    # Category multipliers
    'category_multipliers': {
        'usage_examples': 1.2,
        'configuration': 1.1, 
        'documentation': 0.9,
        'core_code': 1.0,
        'tests': 0.8
    },
    
    # Thompson sampling
    'bandit_initial_alpha': 1.0,
    'bandit_initial_beta': 1.0,
    'bandit_exploration_factor': 0.1,
    
    # Patch system
    'patch_importance_threshold': 0.6,
    'patch_budget_reserve': 0.05,  # Reserve 5% budget for patching
    'max_patch_iterations': 3,
}
```

### Budget-Specific Adjustments

```python
BUDGET_ADJUSTMENTS = {
    50000: {
        'demotion_chunk_threshold': 0.4,  # More aggressive demotion
        'patch_budget_reserve': 0.03,     # Less patch budget
        'quota_adjustments': {
            'core_code': +0.05,           # Prioritize core code
            'tests': -0.03,               # Reduce test inclusion
            'documentation': -0.02
        }
    },
    
    120000: {
        # Use default settings - optimal balance
    },
    
    200000: {
        'demotion_full_threshold': 0.7,   # Less aggressive demotion
        'patch_budget_reserve': 0.08,     # More patch budget
        'quota_adjustments': {
            'documentation': +0.03,       # More comprehensive docs
            'tests': +0.02               # Include more test examples
        }
    }
}
```

### Statistical Analysis Parameters

```python
STATISTICAL_CONFIG = {
    # Bootstrap parameters
    'bootstrap_iterations': 10000,
    'bootstrap_method': 'bca',  # bias-corrected and accelerated
    'confidence_level': 0.95,
    'random_seed': 42,
    
    # Multiple comparison correction
    'fdr_method': 'benjamini_hochberg',
    'family_alpha': 0.05,
    
    # Effect size thresholds
    'small_effect': 0.2,
    'medium_effect': 0.5, 
    'large_effect': 0.8,
    'practical_significance_threshold': 0.13,  # 13% improvement
    
    # Power analysis
    'target_power': 0.8,
    'effect_size_range': (0.1, 2.0),
    'power_curve_points': 20,
    
    # Assumption testing
    'normality_test': 'shapiro_wilk',
    'variance_test': 'levene',
    'alpha_assumption_tests': 0.05
}
```

---

## Data Availability Statement

All evaluation data, statistical analysis results, and source code are available in the accompanying repository:

**GitHub Repository**: [To be provided upon acceptance]
**Zenodo Archive**: [DOI to be assigned upon publication]

**Included Materials**:
- Complete source code for FastPath V5 implementation
- Evaluation benchmark with 36 questions and ground truth answers
- Repository dataset with metadata and dependency graphs
- Statistical analysis scripts and result files
- Figure generation code for all paper visualizations
- Reproducibility instructions and validation scripts

**License**: Apache 2.0 (code), CC-BY 4.0 (data)

---

*Supplementary materials prepared for ICSE 2025 submission*  
*Document version: Final (August 25, 2025)*